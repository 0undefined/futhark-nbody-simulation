An \textit{n}-body simulation is a simulation of \textit{n} number of bodies, as
the name would suggest. We simulate the interactions between all of the
\textit{n} bodies. The bodies are located in a three-dimensional space. In each
tick the simulation calculates the every body (or pointmass) interaction, with
all the other pointmasses in the simulation. The interaction can vary, with
gravitational attraction being the simplest.

If we were to compute the interaction for each body at each step of the
simulation for some $\Delta$ time, naively, we would have a running time of
$O(n^2)$, and since the simulation could be expected to work on very large
values of $n$, as well as the interaction might be timeconsuming to calculate,
it will end up being slow. Therefore we implement a clustered version instead
inspired by the barnes hut algorithm. The idea is that by defining clusters of
bodies we can approximate a region of points, as a single point. The clustered
version is tree-based meaning that we store each pointmass in a tree, and based
on some threshold $\theta$ we determine when we should calculate the interaction
between the actual pointmasses, and when to calculate it for the clustered
representation.

\subsection{Naive simulation}
The naive simulation is simply put, apply the sum of all forces from all
other pointmasses to all pointmasses:         \\
$B: \text{Bodies},$                           \\
$n: |B|,$                                     \\
$b^i_m: \text{mass of } b^i,$                 \\
$b^i_p: \text{position of } b^i $\\
$b^i_f: \text{force of } b^i,$                \\
$\Delta t: \text{Change in time},$                \\
$r(a, b): b_p - a_p, \text{position difference of $a$ and $b$}$\\
$F(a, b): G \cdot a_m \cdot b_m \cdot |r(b - a)|^2 \cdot \left(\frac{1}{|r|} \cdot r\right)$
$$\forall b \in B (\forall a \in B \backslash \left\{ b^i\right\} | b^i_F = \sum F(b^i, a^i))$$

We then apply the force as acceleration scaled with $\Delta t$ on velocity
times $\Delta t$ and apply the velocity as a change in position to each
pointmass in the simulation.

\subsection{Barnes-Hut simulation}
To perform this clustered \textit{n}-body simulation, we make use of the
Barnes-Hut algorithm\cite{BH-algo}. The main idea is to subdivide the space into
regions, when we then want to calculate the interactions between a body ($a$)
and some bodies ($as$) we check how far away $as$'s center-of-mass are from $a$,
if this distance
is too far, based on some threshold, we instead elect to apporximate the
interaction between $a$ and $as$, by using the region containing $as$ as a
single body representation of $as$.

We will now look at two different datastructures that can contain this subdivsion
1) a quadtree, this is typically used for 2D spaces (an octree is used for 3D
spaces), 2) a binary radix-tree, we examine a binary radix-tree since it is used
to create an octree for 3D spaces in \cite{main-ref}, but since Barnes-Hut is
tree agnostic we might be able to create an efficient implementation using a
binary radix-tree.

\subsubsection{Using a quadtree}
As meantioned previously Barnes-Hut subdivides the space containing the bodies.
This is done untill a region of the subdivision contains $0$ or $1$ elements.
We will here describe how it works for a 2D space using a quadtree however this
approach is identical for a 3D space using an octree but it is just easier to
visualize using 2D.

Figure \ref{fig:subdivision} visualizes the subdivision of 2D space into regions
as well as the corresponding quadtree.

\begin{Figure}
  \centering
  \includegraphics[width=0.30\textwidth]{assests/example-space}
  \includegraphics[width=0.65\textwidth]{assests/example-tree}
  \captionof{figure}{A 2D space subdivided into regions with each region
    containing $0$ or $1$ body. The quadtree created from this 2D space can also
    be seen (nw referers to the north west quadrant etc.) \cite{BH-algo}.}
  \label{fig:subdivision}
\end{Figure}

We see in \autoref{fig:subdivision} that each region containing more than one
body is colored gray (we call these nodes internal nodes). Internal nodes will
then store a single pointmass representation of its substree bodies such that if
we were to calculate the interaction between node $H$ and nodes $B, C, D$ and we
find the distance to be too long then we would use the representation stored in
$D$'s parent. If they are not too far apart we traverse the tree recursively
until we reach the leaves. To determine whether or not a node is too distant we
use the quotients $\frac{s}{|d|}$ where $s$ is the width of a region and $|d|$
is the euclidean distance between the centres of masses. We compare this
quotient to a threshold, $\theta$. $\theta$ ends up determining the trade off
between accuracy and performance. If $\theta = 0$ we dont generalize any
pointmasses at all and we end up with the same performance of the naive
implementation (actually a bit slower due to the overhead of constructing the
tree). A common value is $\theta = 0$.

The main advantage of using a quadtree (and octree, by extension) is the evenly
divided regions. If the space is $10$ units wide then we know that the region at
level $3$ of the tree is $1.\overline{6}$; that is $s_r=\frac{w}{2l}$ where
$s_r$ is the width of region $r$, $w$ is the total width of the space, and $l$
is the level. This means that $\theta$ is easy to calculate.

\subsubsection{Using a binary radix-tree}
In \cite{main-ref} a way of constructing a binary radix-tree is presented. We
want the same locality as the quadtree has, that is if two points are close in
$n$-dimensional space (2D specifically for quadtree) so should they be close to
eachother in the tree. To achieve this we use Morton code (also known as a
Z-order curve) \cite{wiki:morton} to order the points. The idea, as in
quadtree, is to construct a tree where each subtree of a node contains bodies
that are close to eachother in $n$-dimensional space (2D specifically for
quadtree). To sort the bodies we order them along a space-filling curve, i.e.
mapping multidimensional data to a single dimension while still keeping
locality.
