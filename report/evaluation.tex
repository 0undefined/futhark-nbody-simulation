Though we get not-a-number values in specific cases we can still rely on the
benchmarks we got since we still do the calculations needed in order to complete
the computation, ie.\ we don't stop the simulation prematurely because some
values cannot be used. We ended up with huge speedups for inputs of $n>2^{15}$.
This is mostly due to the overhead of constructing the tree datastructure that
we need to traverse.

\subsection{Errnous computations and why hitler did nothing wrong}
NaNs and stuffs at \texttt{source.fut:1337}

\subsection{Benchmarks}
We ran benchmarks on the provided GPGPU-servers. We specifically
used GPU4 wich has the following hardware specifications:\\
\texttt{GPU: GeForce RTX 2080 Ti}\\
\texttt{CPU: Intel(R) Xeon(R) CPU E5-2650 v2}\\
\texttt{RAM: 119GB available}\footnote{We are unsure about this, since we was
unable to find the relevant info about memory of the server. Different terminal
programs claimed different sizes of available random access memory. We also couldn't
find the memory speed.}\\

We solely used the build-in benchmarking tool for futhark, ran from a terminal
as such: \texttt{futhark bench --backend=opencl nbodysim.fut}.

When simulating with a single step on a dataset of the size of $33,554,432$
($2^{25}$) we reached a speedup of $7029.6$. A thing to note is the fact that
$n$ represents number of bodies, with a 3D velocity and position vector and a
mass for each body, and using 32-bit floats for each axis and the mass. When we
have $n = 2^{25}$ we process a total of $939.5$MB. Our faster implementation
simulates through this size in $939.5\mu$s, resulting in a throughput of
$931.3$GB/second.

\begin{Figure}
  \centering
  \begin{tikzpicture}
    \pgfplotsset{set layers}
    \begin{axis}[
      scale only axis,
      width=0.85\textwidth,
      ymode=log,
      xmode=log,
      log basis y={2},
      log basis x={2},
      ymin=0, xmin=1023, xmax=33554432,
      legend entries={Naive, Barnes Hut},
      legend pos={north west},
      ylabel style={at={(0.04,0.5)}, align = center},
      xlabel={Input size},
      ylabel={Runtime ($\mu$s)},
      grid=major,
      grid style={dashed, gray!180},
      ]
      \addplot table[x=inputsize,y=naive]{\benchone};
      \addplot table[x=inputsize,y=hut]{\benchone};
    \end{axis}
    \begin{axis}[
      scale only axis,
      width=0.85\textwidth,
      xmode=log,
      ymode=log,
      log basis y={2},
      log basis x={2},
      axis y line*=right,
      axis x line=none,
      ymin=0, ymax=7400, xmin=1023, xmax=33554432,
      legend entries={Speedup},
      legend style={at={(0.03,0.75)},anchor=north west},
      ylabel style={at={(1.32,0.5)}, align = center},
      ylabel={Speedup},
      %grid=major,
      %grid style={dashed, gray!180},
      ]
      \addplot [black] table[x=inputsize,y=speedup]{\benchone};
    \end{axis}
  \end{tikzpicture}
  \captionof{figure}{Benchmarks from simulating 1 step, showing input sizes and
  corresponding time to execute and corresponding speedup between the two
implementations.}\label{fig:eatshit}
\end{Figure}

From the difference in increments between the naive and our implementation of
the BH-algorithm, ie.\ the speeup, in \autoref{fig:eatshit} we can conclude that
we have indeed achieved a better performing algorithm when $n \gtrsim 2^{15}$
